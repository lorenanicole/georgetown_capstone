{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments = pd.read_csv('attack_annotated_comments.tsv', sep='\\t', index_col=0)\n",
    "annotations = pd.read_csv('attack_annotations.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                      comment  year  logged_in  \\\n",
       "rev_id                                                                          \n",
       "37675      `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002      False   \n",
       "44816      `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...  2002      False   \n",
       "49851      NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...  2002      False   \n",
       "89320       Next, maybe you could work on being less cond...  2002       True   \n",
       "93890                   This page will need disambiguation.   2002       True   \n",
       "102817     NEWLINE_TOKEN-NEWLINE_TOKENNEWLINE_TOKENImport...  2002       True   \n",
       "103624     I removed the following:NEWLINE_TOKENNEWLINE_T...  2002       True   \n",
       "111032     `:If you ever claimed in a Judaic studies prog...  2002       True   \n",
       "120283     NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENMy apol...  2002       True   \n",
       "128532     `Someone wrote:NEWLINE_TOKENMore recognizable,...  2002       True   \n",
       "133562     NEWLINE_TOKENNEWLINE_TOKEN:Correct. Full biogr...  2002       True   \n",
       "138117     `NEWLINE_TOKENNEWLINE_TOKENCare should be take...  2002       True   \n",
       "155243     NEWLINE_TOKENNEWLINE_TOKEN:If I may butt in  I...  2002       True   \n",
       "177310     NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENOn my  ...  2002       True   \n",
       "192579     `NEWLINE_TOKENNEWLINE_TOKEN:<>>NEWLINE_TOKENNE...  2002       True   \n",
       "201190           gets far more tendentious yet.NEWLINE_TOKEN  2002       True   \n",
       "208009     `NEWLINE_TOKENNEWLINE_TOKENAs a person who has...  2002       True   \n",
       "249432     It's great that we've found a new source of fr...  2001       True   \n",
       "252031     NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLINE...  2001       True   \n",
       "268558     NEWLINE_TOKENNEWLINE_TOKENI'd like the concept...  2001       True   \n",
       "276906     NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLINE...  2001       True   \n",
       "286174     NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLINE...  2002       True   \n",
       "290598     `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLIN...  2001       True   \n",
       "294124     NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLINE...  2002       True   \n",
       "297866     NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLINE...  2001       True   \n",
       "317177      See? I was right! ;-)  NEWLINE_TOKENNEWLINE_T...  2002       True   \n",
       "336654     NEWLINE_TOKENNEWLINE_TOKEN:I have checked the ...  2002       True   \n",
       "344567     `NEWLINE_TOKENChanged Macedonia link to Macedo...  2002       True   \n",
       "356383     ` NEWLINE_TOKENNEWLINE_TOKEN:Incidentally, re ...  2002       True   \n",
       "358984     `I removed ``from scratch``. In addition to yo...  2002       True   \n",
       "...                                                      ...   ...        ...   \n",
       "699646005   Don't keep changing my page I made please. Yo...  2016       True   \n",
       "699659494  im soory since when is google images not allow...  2016       True   \n",
       "699660419  what ever you fuggin fagNEWLINE_TOKENQuestion ...  2016       True   \n",
       "699661020  NEWLINE_TOKENNEWLINE_TOKEN== Nice try but no c...  2016       True   \n",
       "699661834  `NEWLINE_TOKENNEWLINE_TOKEN== kys ==NEWLINE_TO...  2016       True   \n",
       "699663770  NEWLINE_TOKENNEWLINE_TOKEN== hi Drmies ==NEWLI...  2016       True   \n",
       "699664687   shut up mind your own business and go fuck so...  2016       True   \n",
       "699667660  This talk page is actually a better place to d...  2016       True   \n",
       "699683891  NEWLINE_TOKENNEWLINE_TOKEN== defunct?==NEWLINE...  2016       True   \n",
       "699698850  NEWLINE_TOKENNEWLINE_TOKENYeah, I realized I c...  2016       True   \n",
       "699702006  NEWLINE_TOKEN:There's some weaseling and pov p...  2016       True   \n",
       "699703322  `NEWLINE_TOKEN:::Yeah and in the earlier sente...  2016       True   \n",
       "699715740  `NEWLINE_TOKEN:::::::::::::Again, WP:NOTAFORUM...  2016       True   \n",
       "699728036                      `  [``Those Were the Days``]`  2016       True   \n",
       "699730832  NEWLINE_TOKENNEWLINE_TOKEN== Japanese Scene ==...  2016      False   \n",
       "699732149  NEWLINE_TOKENI am sorry I was only apologizing...  2016       True   \n",
       "699741197  `NEWLINE_TOKENNEWLINE_TOKEN== Jim1138 ==NEWLIN...  2016       True   \n",
       "699753082  NEWLINE_TOKENNEWLINE_TOKEN== Why oh why... ==N...  2016       True   \n",
       "699755057  NEWLINE_TOKENNEWLINE_TOKEN== Daily Beast Artic...  2016       True   \n",
       "699756053  `The lead also lacks proper citation and sourc...  2016       True   \n",
       "699756185  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThe le...  2016       True   \n",
       "699780538          NEWLINE_TOKEN:::::: Well done, thanks!     2016      False   \n",
       "699813325  `NEWLINE_TOKEN::I'm talking about you making u...  2016       True   \n",
       "699820699  `NEWLINE_TOKENYes, from the word ``Guci`` or `...  2016       True   \n",
       "699822249  `NEWLINE_TOKENNEWLINE_TOKEN:``Comment````. Gen...  2016       True   \n",
       "699848324  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThese ...  2016       True   \n",
       "699851288  NEWLINE_TOKENNEWLINE_TOKENThe Institute for Hi...  2016       True   \n",
       "699857133  NEWLINE_TOKEN:The way you're trying to describ...  2016       True   \n",
       "699891012  NEWLINE_TOKENNEWLINE_TOKEN== Warning ==NEWLINE...  2016       True   \n",
       "699897151  Alternate option===NEWLINE_TOKENIs there perha...  2016       True   \n",
       "\n",
       "                ns   sample  split  \n",
       "rev_id                              \n",
       "37675      article   random  train  \n",
       "44816      article   random  train  \n",
       "49851      article   random  train  \n",
       "89320      article   random    dev  \n",
       "93890      article   random  train  \n",
       "102817        user   random  train  \n",
       "103624     article   random  train  \n",
       "111032     article   random    dev  \n",
       "120283     article   random    dev  \n",
       "128532     article   random  train  \n",
       "133562     article   random  train  \n",
       "138117     article   random  train  \n",
       "155243        user   random   test  \n",
       "177310        user   random   test  \n",
       "192579     article   random  train  \n",
       "201190     article   random    dev  \n",
       "208009        user   random  train  \n",
       "249432     article   random  train  \n",
       "252031     article   random  train  \n",
       "268558     article   random  train  \n",
       "276906     article   random  train  \n",
       "286174     article   random   test  \n",
       "290598     article   random    dev  \n",
       "294124     article   random  train  \n",
       "297866     article   random  train  \n",
       "317177     article   random   test  \n",
       "336654        user   random    dev  \n",
       "344567     article   random  train  \n",
       "356383     article   random  train  \n",
       "358984     article   random    dev  \n",
       "...            ...      ...    ...  \n",
       "699646005     user  blocked  train  \n",
       "699659494     user  blocked    dev  \n",
       "699660419     user  blocked   test  \n",
       "699661020     user  blocked  train  \n",
       "699661834     user  blocked   test  \n",
       "699663770     user  blocked  train  \n",
       "699664687     user  blocked    dev  \n",
       "699667660  article  blocked  train  \n",
       "699683891  article  blocked  train  \n",
       "699698850     user  blocked   test  \n",
       "699702006  article  blocked  train  \n",
       "699703322  article  blocked   test  \n",
       "699715740  article  blocked    dev  \n",
       "699728036  article   random  train  \n",
       "699730832  article  blocked    dev  \n",
       "699732149     user   random  train  \n",
       "699741197     user  blocked    dev  \n",
       "699753082     user  blocked   test  \n",
       "699755057  article  blocked    dev  \n",
       "699756053  article  blocked    dev  \n",
       "699756185  article  blocked  train  \n",
       "699780538     user  blocked    dev  \n",
       "699813325  article  blocked  train  \n",
       "699820699     user  blocked    dev  \n",
       "699822249  article  blocked    dev  \n",
       "699848324  article  blocked  train  \n",
       "699851288  article  blocked   test  \n",
       "699857133  article  blocked  train  \n",
       "699891012     user  blocked    dev  \n",
       "699897151  article  blocked  train  \n",
       "\n",
       "[115864 rows x 6 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['comment', 'year', 'logged_in', 'ns', 'sample', 'split'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments['attack'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['comment', 'year', 'logged_in', 'ns', 'sample', 'split', 'attack'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking a comment as example, in this case #103624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I removed the following:NEWLINE_TOKENNEWLINE_TOKENAll names of early Polish rulers are ficticious and therefore this index naming Oda von Haldensleben and her husband Dagome records for the first time rulers of the Polanen tribe. Therefore it is indicated as being the first document of the later developing land named Poland.NEWLINE_TOKENNEWLINE_TOKENThis is quite a comment. All names are fictitious? It deserves at least some backing. '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments['comment'][103624]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parsing: remove newline and tab tokens\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I removed the following:  All names of early Polish rulers are ficticious and therefore this index naming Oda von Haldensleben and her husband Dagome records for the first time rulers of the Polanen tribe. Therefore it is indicated as being the first document of the later developing land named Poland.  This is quite a comment. All names are fictitious? It deserves at least some backing. '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments['comment'][103624]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "phrase_103624=comments['comment'][103624]\n",
    "tokens_103624 = nltk.word_tokenize(phrase_103624)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_103624 = nltk.Text(tokens_103624)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'removed', 'the', 'following', ':', 'All', 'names', 'of', 'early', 'Polish', 'rulers', 'are', 'ficticious', 'and', 'therefore', 'this', 'index', 'naming', 'Oda', 'von', 'Haldensleben', 'and', 'her', 'husband', 'Dagome', 'records', 'for', 'the', 'first', 'time', 'rulers', 'of', 'the', 'Polanen', 'tribe', '.', 'Therefore', 'it', 'is', 'indicated', 'as', 'being', 'the', 'first', 'document', 'of', 'the', 'later', 'developing', 'land', 'named', 'Poland', '.', 'This', 'is', 'quite', 'a', 'comment', '.', 'All', 'names', 'are', 'fictitious', '?', 'It', 'deserves', 'at', 'least', 'some', 'backing', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tokens_103624)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: I removed the following : All names of...>\n"
     ]
    }
   ],
   "source": [
    "print(text_103624)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_103624)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_103624)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_comments=comments['comment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenized_sentences=nltk.sent_tokenize(raw)\n",
    "for each_sentence in tokenized_sentences:\n",
    "   words=nltk.tokenize.word_tokenize(each_sentence)\n",
    "   print each_sentence   #prints tokenized sentences from samp.txt\n",
    "tokenized_words=nltk.word_tokenize(raw)\n",
    "for each_word in tokenized_words:\n",
    "   words=nltk.tokenize.word_tokenize(each_word)\n",
    "   print each_words      #prints tokenized words from samp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict=[]\n",
    "for each_comment in comments['comment']:\n",
    "    dict.append(len(nltk.word_tokenize(each_comment)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how long is the longest one in our dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9949\n"
     ]
    }
   ],
   "source": [
    "print(max(dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "longest in the first 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(dict[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max number of words in a comment is: 9949\n"
     ]
    }
   ],
   "source": [
    "print('The max number of words in a comment is: {}'.format(max(dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "longest_sen = max(all_comments, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST DIE!!!!!!!!!!!!  JIM WALES MUST D\n"
     ]
    }
   ],
   "source": [
    "print(longest_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
