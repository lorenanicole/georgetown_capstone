{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import necessary tools\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# train_test_split split the dataframe into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# CountVectorizer turns the text into a bag-of-words vectors\n",
    "# each tokens acts as a feature for the ML classification problem\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# The goal of using tf-idf instead of the raw frequencies \n",
    "# of occurrence of a token in a given document is to scale down\n",
    "# the impact of tokens that occur very frequently in a given corpus\n",
    "# and that are hence empirically less informative than features \n",
    "# that occur in a small fraction of the training corpus\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# metric model to evaluate the model performance\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data into DataFrame\n",
    "comments = pd.read_csv('attack_annotated_comments.tsv', sep='\\t', index_col=0)\n",
    "annotations = pd.read_csv('attack_annotations.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 115864 unique rev_id\n"
     ]
    }
   ],
   "source": [
    "# print the # of unique rev_id\n",
    "print('There are', len(annotations['rev_id'].unique()), 'unique rev_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels a comment as an attack if the majority of annotators did so\n",
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert column 'labels' in DataFrame 'comments'\n",
    "comments['attack'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parsing: remove \"NEWLINE_TOKEN\" and \"TAB_TOKEN\" tokens from 'comment'\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your DataFrame:\n",
      "\n",
      "                                                  comment  year  logged_in  \\\n",
      "rev_id                                                                       \n",
      "37675   `- This is not ``creative``.  Those are the di...  2002      False   \n",
      "44816   `  :: the term ``standard model`` is itself le...  2002      False   \n",
      "49851     True or false, the situation as of March 200...  2002      False   \n",
      "89320    Next, maybe you could work on being less cond...  2002       True   \n",
      "93890                This page will need disambiguation.   2002       True   \n",
      "\n",
      "             ns  sample  split  attack  \n",
      "rev_id                                  \n",
      "37675   article  random  train   False  \n",
      "44816   article  random  train   False  \n",
      "49851   article  random  train   False  \n",
      "89320   article  random    dev   False  \n",
      "93890   article  random  train   False  \n"
     ]
    }
   ],
   "source": [
    "print('This is your DataFrame:\\n')\n",
    "print(comments.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These is the head of the comments classified as an attack\n",
      "\n",
      "rev_id\n",
      "801279             Iraq is not good  ===  ===  USA is bad   \n",
      "2702703      ____ fuck off you little asshole. If you wan...\n",
      "4632658         i have a dick, its bigger than yours! hahaha\n",
      "6545332      == renault ==  you sad little bpy for drivin...\n",
      "6545351      == renault ==  you sad little bo for driving...\n",
      "Name: comment, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('These is the head of the comments classified as an attack\\n')\n",
    "print(comments.query('attack')['comment'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create y which is the outcome label the model has to learn\n",
    "y = comments['attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(comments['comment'], y, test_size=0.33, random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ngram_range(1, 2) means unigrams and bigrams\n",
    "vectorizer = CountVectorizer(max_features=10000, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Tf-idf Transformer\n",
    "count_train = vectorizer.fit_transform(X_train)\n",
    "tf_transformer = TfidfTransformer(norm = 'l2')\n",
    "count_train = tf_transformer.fit_transform(count_train)\n",
    "\n",
    "count_test = vectorizer.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_classifier = LogisticRegression()\n",
    "lr_classifier.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = lr_classifier.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786457788472\n"
     ]
    }
   ],
   "source": [
    "# testing accuracy\n",
    "print(metrics.accuracy_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25914  7757]\n",
      " [  408  4157]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.98      0.77      0.86     33671\n",
      "       True       0.35      0.91      0.50      4565\n",
      "\n",
      "avg / total       0.91      0.79      0.82     38236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, pred, labels=[False, True]))\n",
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
